{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "In this lab, an example of applying the Support Vector Machines (SVM) for classification is presented.\n",
    "\n",
    "Some of the content in this lab tutorial is taken from the:\n",
    "1. Datacamp's SVM tutorial by Avinash Navlani (https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python) and \n",
    "2. Kaggle's SVM on iris flower dataset (https://www.kaggle.com/arshid/support-vector-machine-on-iris-flower-dataset)\n",
    "\n",
    "The iris dataset contains measurements for 150 iris flowers from three different species.\n",
    "\n",
    "The three classes in the Iris dataset:\n",
    "\n",
    "    Iris-setosa (n=50)\n",
    "    Iris-versicolor (n=50)\n",
    "    Iris-virginica (n=50)\n",
    "\n",
    "The four features of the Iris dataset:\n",
    "\n",
    "    sepal length in cm\n",
    "    sepal width in cm\n",
    "    petal length in cm\n",
    "    petal width in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with only two classes and two features\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the features and target\n",
    "print('Features: ', iris.feature_names)\n",
    "print('Labels: ', iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the data\n",
    "print(iris.data.shape)\n",
    "\n",
    "# Check if any of the attribute has a nan value.\n",
    "np.isnan(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data\n",
    "\n",
    "In most cases, we would like first to see the data plot. This could provide more insights on the data, before further analysis takes place. We will use the seaborn pairplot to visualise the data, to see the similarities or differences between classes. First we need to convert the data to pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "data1['species'] = iris['target']\n",
    "data1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lambda function is used to apply a function to convert the target values which \n",
    "# are 0,1,2 to the corresponding target values(“setosa”,”versicolor”,”virginica”) \n",
    "# for better understanding.\n",
    "data1['species'] = data1['species'].apply(lambda x:iris['target_names'][x])\n",
    "data1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pairplot to visualize the similarities and especially difference between the species\n",
    "sns.pairplot(data=data1, hue='species', palette='Set1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "Next, we split the data to training and test sets.\n",
    "\n",
    "The training set will be used to generate the model (SVM will learn pattern of Iris dataset using this training set).\n",
    "\n",
    "The test set will be used to evaluate how good the generated model is in distinguishing different types of Iris flowers.\n",
    "\n",
    "In this example, we set 20% of the data as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set, 80% training and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create support vector classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "# Train model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the accuracy of the prediction. Accuracy can be computed by comparing the predicted label and the actual label of the test data. We also would like to see which label is correctly predicted, and which is not. We can use the confusion matrix to see this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# The classification confusion matrix\n",
    "cm = np.array(metrics.confusion_matrix(y_test, y_pred))\n",
    "confusion = pd.DataFrame(cm, index=['is_setosa','is_versicolor','is_virginica'],\n",
    "                        columns=['pred_setosa','pred_versicolor','pred_virginica'])\n",
    "print(confusion)\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy: %.2f\" % metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters\n",
    "\n",
    "Kernel: The main function of the kernel is to transform the given dataset input data into the required form. There are various types of functions such as linear, polynomial, and radial basis function (RBF). Polynomial and RBF are useful for non-linear hyperplane. Polynomial and RBF kernels compute the separation line in the higher dimension. In some of the applications, it is suggested to use a more complex kernel to separate the classes that are curved or nonlinear. This transformation can lead to more accurate classifiers.\n",
    "\n",
    "Regularization: Regularization parameter in python's Scikit-learn C parameter used to maintain regularization. Here C is the penalty parameter, which represents misclassification or error term. The misclassification or error term tells the SVM optimization how much error is bearable. This is how you can control the trade-off between decision boundary and misclassification term. A smaller value of C creates a small-margin hyperplane and a larger value of C creates a larger-margin hyperplane.\n",
    "\n",
    "Gamma: A lower value of Gamma will loosely fit the training dataset, whereas a higher value of gamma will exactly fit the training dataset, which causes over-fitting. In other words, you can say a low value of gamma considers only nearby points in calculating the separation line, while the a value of gamma considers all the data points in the calculation of the separation line.\n",
    "\n",
    "You may change the parameters of the classifier above and identify which paramater setting produced the best accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
